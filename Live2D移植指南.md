# My-Neuroå‰ç«¯æ•°å­—äººç§»æ¤åˆ°NagaAgenté¡¹ç›®æŒ‡å—

## é¡¹ç›®åˆ†ææ¦‚è¿°

### æºé¡¹ç›®ï¼ˆMy-Neuroï¼‰ç‰¹ç‚¹ - ä¿®æ­£ç‰ˆ
- **å‰ç«¯æŠ€æœ¯**: PyQt5 + OpenGL + Live2D Cubism SDK for Python
- **æ ¸å¿ƒåŠŸèƒ½**: Live2Dæ•°å­—äººæ¸²æŸ“ã€æƒ…ç»ªåŠ¨ä½œåŒæ­¥ã€å˜´å‹åŒæ­¥ã€è¯­éŸ³äº¤äº’
- **æ¶æ„**: å•ä¸€Pythonåº”ç”¨ï¼Œäº‹ä»¶é©±åŠ¨è®¾è®¡
- **é€šä¿¡æ–¹å¼**: å†…éƒ¨äº‹ä»¶æ€»çº¿ï¼Œæ— WebSocketé€šä¿¡
- **å·²å®ç°åŠŸèƒ½**: å®Œæ•´çš„Live2Dæ§ä»¶ã€å˜´å‹åŒæ­¥ã€æƒ…ç»ªå¤„ç†

### ç›®æ ‡é¡¹ç›®ï¼ˆNagaAgentï¼‰ç‰¹ç‚¹
- **æŠ€æœ¯æ ˆ**: Python + PyQt5 + FastAPI
- **ç°æœ‰åŠŸèƒ½**: æ–‡æœ¬å¯¹è¯ã€è¯­éŸ³åˆæˆã€APIæœåŠ¡ã€å·¥å…·è°ƒç”¨
- **æ¶æ„**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒæ’ä»¶æ‰©å±•
- **UIç³»ç»Ÿ**: åŸºäºPyQt5çš„ç°ä»£åŒ–ç•Œé¢

## ç§»æ¤æ–¹æ¡ˆè®¾è®¡ - ä¿®æ­£ç‰ˆ

### æ–¹æ¡ˆä¸€ï¼šPythonæ¨¡å—é›†æˆï¼ˆæ¨èï¼‰
å°†My-Neuroçš„Live2Dç›¸å…³æ¨¡å—ç›´æ¥é›†æˆåˆ°NagaAgentä¸­ï¼Œä¿æŒPythonæŠ€æœ¯æ ˆã€‚

### æ–¹æ¡ˆäºŒï¼šç‹¬ç«‹è¿›ç¨‹æ¨¡å¼
Live2Dä½œä¸ºç‹¬ç«‹è¿›ç¨‹è¿è¡Œï¼Œé€šè¿‡APIä¸NagaAgenté€šä¿¡ã€‚

### æ–¹æ¡ˆä¸‰ï¼šWebç‰ˆæœ¬ç§»æ¤
å°†Live2Dç§»æ¤åˆ°Webç‰ˆæœ¬ï¼Œé€šè¿‡æµè§ˆå™¨è®¿é—®ã€‚

## è¯¦ç»†ç§»æ¤æ­¥éª¤ - ä¿®æ­£ç‰ˆ

### æ­¥éª¤1ï¼šé¡¹ç›®ç»“æ„è§„åˆ’

åœ¨NagaAgenté¡¹ç›®ä¸­åˆ›å»ºæ–°çš„Live2Dæ¨¡å—ç›®å½•ï¼š

```
NagaAgent/
â”œâ”€â”€ live2d_module/                # æ–°å¢Live2Dæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ live2d_widget.py          # Live2Dä¸»æ§ä»¶ï¼ˆåŸºäºMy-Neuroï¼‰
â”‚   â”œâ”€â”€ lip_sync_thread.py        # å˜´å‹åŒæ­¥çº¿ç¨‹
â”‚   â”œâ”€â”€ emotion_handler.py        # æƒ…ç»ªå¤„ç†å™¨
â”‚   â”œâ”€â”€ audio_integration.py      # éŸ³é¢‘é›†æˆé€‚é…å™¨
â”‚   â”œâ”€â”€ event_adapter.py          # äº‹ä»¶æ€»çº¿é€‚é…å™¨
â”‚   â”œâ”€â”€ models/                   # Live2Dæ¨¡å‹æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ hiyori_pro_mic.model3.json
â”‚   â”‚   â”œâ”€â”€ hiyori_pro_mic.moc3
â”‚   â”‚   â””â”€â”€ motions/               # åŠ¨ä½œæ–‡ä»¶
â”‚   â””â”€â”€ config/                   # é…ç½®æ–‡ä»¶
â”‚       â””â”€â”€ live2d_config.json
â”œâ”€â”€ ui/                           # ç°æœ‰UIæ¨¡å—
â”‚   â”œâ”€â”€ components/               # UIç»„ä»¶
â”‚   â””â”€â”€ live2d_settings.py        # Live2Dè®¾ç½®ç•Œé¢
â”œâ”€â”€ apiserver/                    # APIæœåŠ¡å™¨
â”‚   â”œâ”€â”€ live2d_api.py            # Live2Dç›¸å…³API
â”‚   â””â”€â”€ audio_api.py             # éŸ³é¢‘APIé€‚é…
â”œâ”€â”€ config.py                     # ä¸»é…ç½®æ–‡ä»¶
â””â”€â”€ main.py                       # ä¸»ç¨‹åº
```

### æ­¥éª¤2ï¼šæ ¸å¿ƒæ–‡ä»¶ç§»æ¤ - Pythonç‰ˆæœ¬

#### 2.1 å¤åˆ¶My-Neuroçš„æ ¸å¿ƒLive2Dæ–‡ä»¶

**å¤åˆ¶Live2Dæ§ä»¶å®ç°**ï¼š
```bash
# åˆ›å»ºç›®æ ‡ç›®å½•
mkdir -p NagaAgent/live2d_module

# å¤åˆ¶My-Neuroçš„Live2Dæ ¸å¿ƒæ–‡ä»¶
cp /mnt/d/code/pythonWork/my-neuro/py-my-neuro/UI/live2d_model.py NagaAgent/live2d_module/
cp /mnt/d/code/pythonWork/my-neuro/py-my-neuro/UI/lip_sync_thread.py NagaAgent/live2d_module/
cp /mnt/d/code/pythonWork/my-neuro/py-my-neuro/UI/simple_event_bus.py NagaAgent/live2d_module/event_adapter.py

# å¤åˆ¶Live2Dæ¨¡å‹æ–‡ä»¶
cp -r /mnt/d/code/pythonWork/my-neuro/py-my-neuro/UI/2D/* NagaAgent/live2d_module/models/
```

#### 2.2 ä¿®æ”¹Live2Dæ§ä»¶é€‚é…NagaAgent

**ä¿®æ”¹Live2Dä¸»æ§ä»¶**ï¼š
```python
# NagaAgent/live2d_module/live2d_widget.py
import os
import sys
import time
import win32gui
import win32con
import OpenGL.GL as gl
import numpy as np
import logging
import asyncio
from PyQt5.QtCore import QTimerEvent, Qt, pyqtSignal, QThread, QEvent, pyqtSlot, QMetaObject, Q_ARG
from PyQt5.QtGui import QMouseEvent, QCursor, QSurfaceFormat
from PyQt5.QtWidgets import QOpenGLWidget, QApplication
from PyQt5.QtGui import QGuiApplication

from .lip_sync_thread import LipSyncThread
from .event_adapter import event_bus  # ä½¿ç”¨é€‚é…åçš„äº‹ä»¶æ€»çº¿
import live2d.v3 as live2d
from live2d.v3 import StandardParams

logger = logging.getLogger("live2d_widget")

class NagaLive2DWidget(QOpenGLWidget):
    """NagaAgent Live2Dæ•°å­—äººæ§ä»¶ï¼ˆåŸºäºMy-Neuroå®ç°ï¼‰"""

    # å®šä¹‰ä¿¡å·
    model_clicked = pyqtSignal(float, float)
    model_dragged = pyqtSignal(float, float)
    model_loaded = pyqtSignal()
    emotion_triggered = pyqtSignal(str, float)  # æƒ…ç»ªè§¦å‘ä¿¡å·

    def __init__(self, config=None, parent=None):
        super().__init__(parent)
        
        # é…ç½®åˆå§‹åŒ–
        self.config = config or {}
        self.model_path = self.config.get("model_path", "models/hiyori_pro_mic.model3.json")
        self.scale = self.config.get("scale", 1.0)
        
        # çª—å£è®¾ç½®ï¼ˆä¿æŒMy-Neuroçš„é€æ˜çª—å£ç‰¹æ€§ï¼‰
        self.setWindowFlags(
            Qt.WindowType.FramelessWindowHint |
            Qt.WindowType.Tool |
            Qt.WindowType.WindowStaysOnTopHint
        )
        self.setAttribute(Qt.WA_TranslucentBackground, True)
        
        # è®¾ç½®åˆ†å±‚çª—å£å’Œç©¿é€å±æ€§
        self.hwnd = int(self.winId())
        win32gui.SetWindowLong(
            self.hwnd,
            win32con.GWL_EXSTYLE,
            win32gui.GetWindowLong(self.hwnd, win32con.GWL_EXSTYLE) |
            win32con.WS_EX_LAYERED |
            win32con.WS_EX_TRANSPARENT
        )
        win32gui.SetLayeredWindowAttributes(self.hwnd, 0, 255, win32con.LWA_ALPHA)
        
        # æ¨¡å‹ä½ç½®å’ŒçŠ¶æ€
        self.model_offset_x = self.config.get("offset_x", 1050)
        self.model_offset_y = self.config.get("offset_y", 600)
        self.isInModelArea = False
        self.isClickingModel = False
        self.screen_size = QGuiApplication.primaryScreen().geometry()
        
        # è®¾ç½®çª—å£å¤§å°
        self.resize(self.screen_size.width()+1, self.screen_size.height())
        self.move(
            (self.screen_size.width()-self.frameGeometry().width())//2,
            (self.screen_size.height()-self.frameGeometry().height())//2
        )
        
        # Live2Dç›¸å…³
        self.model = None
        self.is_talking = False
        self.is_listening = False
        self.current_expression = ""
        self.lip_sync_intensity = 3.0
        self.lip_sync_thread = None
        
        # åŠ¨ä½œç›¸å…³
        self.tapbody_motions = []
        self.current_tapbody_idx = 0
        self.is_playing_tapbody = False
        self.motion_group_name = None
        
        logger.info("NagaAgent Live2Dæ§ä»¶åˆå§‹åŒ–å®Œæˆ")
        
    def initializeGL(self):
        """åˆå§‹åŒ–OpenGLå’ŒLive2Dæ¨¡å‹"""
        try:
            self.makeCurrent()
            
            # åˆå§‹åŒ–Live2D
            if hasattr(live2d, 'LIVE2D_VERSION') and live2d.LIVE2D_VERSION == 3:
                try:
                    live2d.glInit()
                    logger.info("Live2D glInit æˆåŠŸ")
                except Exception as e:
                    logger.error(f"Live2D glInit å¤±è´¥: {e}")
            
            # åˆ›å»ºæ¨¡å‹å®ä¾‹
            self.model = live2d.LAppModel()
            logger.info("Live2D æ¨¡å‹å®ä¾‹åˆ›å»ºæˆåŠŸ")
            
            # åŠ è½½æ¨¡å‹
            model_loaded = False
            if os.path.exists(self.model_path):
                try:
                    self.model.LoadModelJson(self.model_path)
                    logger.info(f"ä»é…ç½®è·¯å¾„åŠ è½½æ¨¡å‹æˆåŠŸ: {self.model_path}")
                    model_loaded = True
                except Exception as e:
                    logger.error(f"ä»é…ç½®è·¯å¾„åŠ è½½æ¨¡å‹å¤±è´¥: {self.model_path}, é”™è¯¯: {e}")
            
            if not model_loaded:
                # è‡ªåŠ¨æœç´¢æ¨¡å‹æ–‡ä»¶
                search_dirs = ["models", "."]
                for search_dir in search_dirs:
                    if not os.path.exists(search_dir):
                        continue
                    
                    try:
                        for file in os.listdir(search_dir):
                            if file.endswith('.model3.json'):
                                model_path = os.path.join(search_dir, file)
                                try:
                                    self.model.LoadModelJson(model_path)
                                    logger.info(f"è‡ªåŠ¨å‘ç°å¹¶åŠ è½½æ¨¡å‹: {model_path}")
                                    model_loaded = True
                                    break
                                except Exception as e:
                                    logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {model_path}, é”™è¯¯: {e}")
                        
                        if model_loaded:
                            break
                    except Exception as e:
                        logger.error(f"æœç´¢ç›®å½•å¤±è´¥: {search_dir}, é”™è¯¯: {e}")
            
            # è®¾ç½®æ¨¡å‹å‚æ•°
            if self.model:
                self.model.SetScale(self.scale)
                
                # è®¾ç½®æ¨¡å‹ä½ç½®
                canvas_w, canvas_h = self.model.GetCanvasSize()
                self.model.SetOffset(
                    (self.model_offset_x - canvas_w / 2) / (self.screen_size.height() / 2),
                    (-self.model_offset_y + canvas_h / 2) / (self.screen_size.height() / 2)
                )
                logger.info(f"è®¾ç½®æ¨¡å‹åç§»: x={self.model_offset_x}, y={self.model_offset_y}")
            
            # åˆå§‹åŒ–åŠ¨ä½œåˆ—è¡¨
            self.setup_motion_list()
            
            # å¯åŠ¨æ¸²æŸ“å®šæ—¶å™¨
            self.startTimer(int(1000 / 60))  # 60FPS
            
            # å‘é€æ¨¡å‹åŠ è½½å®Œæˆä¿¡å·
            self.model_loaded.emit()
            logger.info("Live2Dæ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–Live2Dæ¨¡å‹å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            
    def setup_motion_list(self):
        """åˆå§‹åŒ–åŠ¨ä½œåˆ—è¡¨"""
        if self.model:
            try:
                motions = self.model.GetMotionGroups()
                
                # ç¡®å®šåŠ¨ä½œç»„åç§°
                self.motion_group_name = None
                if "TapBody" in motions:
                    self.motion_group_name = "TapBody"
                elif "Tap" in motions:
                    self.motion_group_name = "Tap"
                else:
                    print("æœªæ‰¾åˆ°TapBodyæˆ–TapåŠ¨ä½œç»„")
                    return
                
                # è·å–åŠ¨ä½œæ•°é‡
                motion_count = motions[self.motion_group_name]
                self.tapbody_motions = list(range(motion_count))
                
                print(f"=== Live2D {self.motion_group_name}åŠ¨ä½œåˆ—è¡¨ ===")
                print(f"{self.motion_group_name}ç»„å…± {motion_count} ä¸ªåŠ¨ä½œ")
                
            except Exception as e:
                logger.error(f"è·å–åŠ¨ä½œåˆ—è¡¨å¤±è´¥: {e}")
                
    def trigger_emotion(self, emotion_name, intensity=1.0):
        """è§¦å‘æƒ…ç»ªåŠ¨ä½œï¼ˆé€‚é…NagaAgentï¼‰"""
        try:
            if self.model:
                # æ ¹æ®æƒ…ç»ªåç§°æ˜ å°„åˆ°åŠ¨ä½œ
                emotion_map = {
                    "å¼€å¿ƒ": "TapBody",
                    "ç”Ÿæ°”": "TapBody", 
                    "ä¼¤å¿ƒ": "TapBody",
                    "æƒŠè®¶": "TapBody",
                    "å®³ç¾": "TapBody"
                }
                
                motion_group = emotion_map.get(emotion_name, "TapBody")
                
                # éšæœºé€‰æ‹©ä¸€ä¸ªåŠ¨ä½œ
                if self.tapbody_motions:
                    motion_idx = np.random.choice(self.tapbody_motions)
                    self.model.StartMotion(motion_group, motion_idx, 3)
                    self.is_playing_tapbody = True
                    
                # è®¾ç½®è¡¨æƒ…
                if emotion_name in ["å¼€å¿ƒ", "ç”Ÿæ°”", "ä¼¤å¿ƒ", "æƒŠè®¶", "å®³ç¾"]:
                    self.set_expression(emotion_name)
                
                # å‘é€æƒ…ç»ªè§¦å‘ä¿¡å·
                self.emotion_triggered.emit(emotion_name, intensity)
                
                logger.info(f"è§¦å‘æƒ…ç»ª: {emotion_name}, å¼ºåº¦: {intensity}")
                
        except Exception as e:
            logger.error(f"è§¦å‘æƒ…ç»ªå¤±è´¥: {e}")
            
    def start_lip_sync(self, audio_path):
        """å¼€å§‹å˜´å‹åŒæ­¥"""
        if not audio_path or not os.path.exists(audio_path):
            logger.error(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            return False
            
        # åœæ­¢ä¹‹å‰çš„å˜´å‹åŒæ­¥
        self.stop_lip_sync()
        
        try:
            # åˆ›å»ºå¹¶å¯åŠ¨å˜´å‹åŒæ­¥çº¿ç¨‹
            self.lip_sync_thread = LipSyncThread(audio_path, event_bus, self.lip_sync_intensity)
            
            # è¿æ¥ä¿¡å·
            self.lip_sync_thread.update_signal.connect(self._update_mouth)
            self.lip_sync_thread.finished_signal.connect(self.on_lip_sync_finished)
            self.lip_sync_thread.error_signal.connect(self.on_lip_sync_error)
            
            # å¯åŠ¨çº¿ç¨‹
            self.lip_sync_thread.start()
            
            return True
            
        except Exception as e:
            logger.error(f"å¯åŠ¨å˜´å‹åŒæ­¥å¤±è´¥: {e}")
            return False
            
    def stop_lip_sync(self):
        """åœæ­¢å˜´å‹åŒæ­¥"""
        if self.lip_sync_thread:
            self.lip_sync_thread.stop()
            self.lip_sync_thread = None
            
            # é‡ç½®å˜´éƒ¨å‚æ•°
            if self.model:
                try:
                    self.model.SetParameterValue(StandardParams.ParamMouthOpenY, 0.0)
                except Exception as e:
                    logger.error(f"é‡ç½®å˜´éƒ¨å‚æ•°å¤±è´¥: {e}")
                    
    @pyqtSlot(float)
    def _update_mouth(self, value):
        """æ›´æ–°å˜´å‹å‚æ•°"""
        if self.model:
            try:
                from live2d.v3 import StandardParams
                self.model.SetParameterValue(StandardParams.ParamMouthOpenY, value)
            except:
                pass
            
            try:
                self.model.SetParameterValue("PARAM_MOUTH_OPEN_Y", value)
            except:
                pass
                
    def set_expression(self, expression):
        """è®¾ç½®è¡¨æƒ…"""
        if self.model:
            try:
                self.model.SetExpression(expression)
                self.current_expression = expression
                logger.debug(f"è®¾ç½®è¡¨æƒ…: {expression}")
            except Exception as e:
                logger.error(f"è®¾ç½®è¡¨æƒ…å¤±è´¥: {e}")
                
    def paintGL(self):
        """æ¸²æŸ“æ¨¡å‹"""
        try:
            live2d.clearBuffer()
            
            if self.model:
                # æ›´æ–°æ¨¡å‹
                self.model.Update()
                
                # å¤„ç†åŠ¨ä½œçŠ¶æ€
                if self.model.IsMotionFinished():
                    if self.is_playing_tapbody:
                        self.is_playing_tapbody = False
                        
                    # æ ¹æ®çŠ¶æ€æ’­æ”¾å¯¹åº”åŠ¨ä½œ
                    if self.is_talking:
                        self.model.StartMotion("Talk", 0, 2)
                    elif self.is_listening:
                        self.model.StartMotion("Listen", 0, 2)
                    else:
                        self.model.StartMotion("Idle", 0, 1)
                
                # ç»˜åˆ¶æ¨¡å‹
                self.model.Draw()
                
        except Exception as e:
            logger.error(f"æ¸²æŸ“æ¨¡å‹å¤±è´¥: {e}")
            
    def timerEvent(self, event):
        """å®šæ—¶å™¨äº‹ä»¶"""
        if not self.isVisible():
            return
            
        try:
            # æ›´æ–°çª—å£ç©¿é€å±æ€§
            current_style = win32gui.GetWindowLong(self.hwnd, win32con.GWL_EXSTYLE)
            local_x, local_y = QCursor.pos().x() - self.x(), QCursor.pos().y() - self.y()
            
            in_model_area = self.check_in_model_area(local_x, local_y)
            
            if in_model_area:
                new_style = current_style & ~win32con.WS_EX_TRANSPARENT
                self.isInModelArea = True
            else:
                new_style = current_style | win32con.WS_EX_TRANSPARENT
                self.isInModelArea = False
                
            if new_style != current_style:
                win32gui.SetWindowLong(self.hwnd, win32con.GWL_EXSTYLE, new_style)
                win32gui.SetLayeredWindowAttributes(self.hwnd, 0, 255, win32con.LWA_ALPHA)
                
            # è¯·æ±‚é‡ç»˜
            self.update()
            
        except Exception as e:
            logger.error(f"å®šæ—¶å™¨äº‹ä»¶å¤„ç†å¤±è´¥: {e}")
            
    def check_in_model_area(self, x, y):
        """æ£€æŸ¥åæ ‡æ˜¯å¦åœ¨æ¨¡å‹åŒºåŸŸå†…"""
        try:
            systemScale = QGuiApplication.primaryScreen().devicePixelRatio()
            gl_x = int(x * systemScale)
            gl_y = int((self.height() - y) * systemScale)
            
            if (gl_x < 0 or gl_y < 0 or
                gl_x >= self.width() * systemScale or
                gl_y >= self.height() * systemScale):
                return False
                
            alpha = gl.glReadPixels(gl_x, gl_y, 1, 1, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE)[3]
            return alpha > 50
            
        except Exception as e:
            logger.error(f"åˆ¤æ–­æ¨¡å‹åŒºåŸŸå¤±è´¥: {e}")
            return False
            
    def set_talking(self, is_talking):
        """è®¾ç½®è¯´è¯çŠ¶æ€"""
        self.is_talking = is_talking
        logger.debug(f"è®¾ç½®è¯´è¯çŠ¶æ€: {is_talking}")
        
    def set_listening(self, is_listening):
        """è®¾ç½®è†å¬çŠ¶æ€"""
        self.is_listening = is_listening
        logger.debug(f"è®¾ç½®è†å¬çŠ¶æ€: {is_listening}")
        
    def closeEvent(self, event):
        """çª—å£å…³é—­äº‹ä»¶"""
        try:
            self.stop_lip_sync()
        except:
            pass
        super().closeEvent(event)
        
    def __del__(self):
        """ææ„å‡½æ•°"""
        self.stop_lip_sync()
```

#### 2.3 åˆ›å»ºéŸ³é¢‘é›†æˆé€‚é…å™¨

**åˆ›å»ºéŸ³é¢‘å¤„ç†æ¨¡å—**ï¼š
```python
# NagaAgent/live2d_module/audio_integration.py
import os
import tempfile
import logging
import requests
import aiohttp
from typing import Optional, Dict, Any
from .event_adapter import event_bus

logger = logging.getLogger("live2d_audio")

class Live2DAudioAdapter:
    """Live2DéŸ³é¢‘é€‚é…å™¨ - è¿æ¥NagaAgentéŸ³é¢‘ç³»ç»Ÿ"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.tts_enabled = self.config.get("tts_enabled", True)
        self.asr_enabled = self.config.get("asr_enabled", True)
        
        # è¿œç¨‹æœåŠ¡é…ç½®
        self.tts_api_url = self.config.get("tts_api_url", "http://127.0.0.1:8000/voice/speak")
        self.asr_api_url = self.config.get("asr_api_url", "http://127.0.0.1:8000/voice/transcribe")
        
        # æœ¬åœ°TTSé…ç½®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        self.local_tts_path = self.config.get("local_tts_path", None)
        
        logger.info("Live2DéŸ³é¢‘é€‚é…å™¨åˆå§‹åŒ–å®Œæˆ")
        
    async def text_to_speech(self, text: str, output_path: Optional[str] = None) -> str:
        """æ–‡æœ¬è½¬è¯­éŸ³ï¼Œè¿”å›éŸ³é¢‘æ–‡ä»¶è·¯å¾„"""
        try:
            # å¦‚æœé…ç½®äº†æœ¬åœ°TTSï¼Œä¼˜å…ˆä½¿ç”¨
            if self.local_tts_path and os.path.exists(self.local_tts_path):
                return await self._local_tts(text, output_path)
            
            # ä½¿ç”¨è¿œç¨‹TTS API
            return await self._remote_tts(text, output_path)
            
        except Exception as e:
            logger.error(f"TTSè½¬æ¢å¤±è´¥: {e}")
            return None
            
    async def _local_tts(self, text: str, output_path: Optional[str] = None) -> str:
        """æœ¬åœ°TTSå¤„ç†"""
        try:
            # è¿™é‡Œå¯ä»¥é›†æˆNagaAgentçš„æœ¬åœ°TTSæ¨¡å—
            # ç›®å‰å…ˆä½¿ç”¨è¿œç¨‹API
            return await self._remote_tts(text, output_path)
            
        except Exception as e:
            logger.error(f"æœ¬åœ°TTSå¤±è´¥: {e}")
            raise
            
    async def _remote_tts(self, text: str, output_path: Optional[str] = None) -> str:
        """è¿œç¨‹TTS APIè°ƒç”¨"""
        try:
            if not output_path:
                output_path = tempfile.mktemp(suffix='.wav')
            
            # è°ƒç”¨NagaAgentçš„TTS API
            async with aiohttp.ClientSession() as session:
                data = {
                    "text": text,
                    "text_language": "zh",
                    "format": "wav"
                }
                
                async with session.post(self.tts_api_url, json=data) as response:
                    if response.status == 200:
                        audio_data = await response.read()
                        
                        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
                        with open(output_path, 'wb') as f:
                            f.write(audio_data)
                        
                        logger.info(f"TTSè½¬æ¢æˆåŠŸ: {output_path}")
                        return output_path
                    else:
                        logger.error(f"TTS APIè°ƒç”¨å¤±è´¥: {response.status}")
                        return None
                        
        except Exception as e:
            logger.error(f"è¿œç¨‹TTSå¤±è´¥: {e}")
            return None
            
    async def speech_to_text(self, audio_path: str) -> str:
        """è¯­éŸ³è½¬æ–‡æœ¬"""
        try:
            if not self.asr_enabled:
                return None
                
            async with aiohttp.ClientSession() as session:
                with open(audio_path, 'rb') as audio_file:
                    data = aiohttp.FormData()
                    data.add_field('audio', audio_file, filename=os.path.basename(audio_path))
                    
                    async with session.post(self.asr_api_url, data=data) as response:
                        if response.status == 200:
                            result = await response.json()
                            return result.get('text', '')
                        else:
                            logger.error(f"ASR APIè°ƒç”¨å¤±è´¥: {response.status}")
                            return None
                            
        except Exception as e:
            logger.error(f"ASRè½¬æ¢å¤±è´¥: {e}")
            return None
            
    def get_audio_duration(self, audio_path: str) -> float:
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        try:
            import wave
            with wave.open(audio_path, 'rb') as wav_file:
                frames = wav_file.getnframes()
                sample_rate = wav_file.getframerate()
                return frames / sample_rate
                
        except Exception as e:
            logger.error(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
            return 0.0
```

#### 2.4 åˆ›å»ºæƒ…ç»ªå¤„ç†å™¨

**æƒ…ç»ªå¤„ç†æ¨¡å—**ï¼š
```python
# NagaAgent/live2d_module/emotion_handler.py
import logging
import re
import asyncio
from typing import Dict, List, Tuple, Any
from .event_adapter import event_bus

logger = logging.getLogger("live2d_emotion")

class Live2DEmotionHandler:
    """Live2Dæƒ…ç»ªå¤„ç†å™¨ - é€‚é…NagaAgentå¯¹è¯ç³»ç»Ÿ"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.enabled = self.config.get("enabled", True)
        self.emotion_keywords = self._load_emotion_keywords()
        self.current_emotion = "neutral"
        self.emotion_intensity = 1.0
        
        # è®¢é˜…äº‹ä»¶
        event_bus.subscribe("ai_response_start", self._on_ai_response_start)
        event_bus.subscribe("ai_text_chunk", self._on_ai_text_chunk)
        event_bus.subscribe("ai_response_end", self._on_ai_response_end)
        
        logger.info("Live2Dæƒ…ç»ªå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        
    def _load_emotion_keywords(self) -> Dict[str, List[str]]:
        """åŠ è½½æƒ…ç»ªå…³é”®è¯"""
        return {
            "å¼€å¿ƒ": [
                "å¼€å¿ƒ", "é«˜å…´", "å¿«ä¹", "å“ˆå“ˆ", "å‘µå‘µ", "å˜»å˜»", 
                "ğŸ˜Š", "ğŸ™‚", "ğŸ˜„", "ğŸ˜ƒ", "happy", "å“ˆå“ˆ", "ç¬‘",
                "å¤ªå¥½äº†", "æ£’æäº†", "å¤ªæ£’äº†", "å®Œç¾", "ä¼˜ç§€"
            ],
            "ç”Ÿæ°”": [
                "ç”Ÿæ°”", "æ„¤æ€’", "è®¨åŒ", "æ°”æ­»", "æ¼ç«", 
                "ğŸ˜ ", "ğŸ˜¡", "mad", "angry", "æ€’",
                "æ··è›‹", "å¯æ¶", "çƒ¦æ­»äº†", "æ°”äºº"
            ],
            "ä¼¤å¿ƒ": [
                "ä¼¤å¿ƒ", "éš¾è¿‡", "æ‚²ä¼¤", "å“­", "éš¾è¿‡", 
                "ğŸ˜¢", "ğŸ˜­", "ğŸ˜", "ğŸ˜”", "sad", "cry",
                "ç—›è‹¦", "å¿ƒç—›", "å¿ƒç–¼", "é—æ†¾"
            ],
            "æƒŠè®¶": [
                "æƒŠè®¶", "éœ‡æƒŠ", "å“‡", "å¤©å•Š", "ä¸ä¼šå§", 
                "ğŸ˜®", "ğŸ˜²", "ğŸ˜¯", "wow", "amazing",
                "çœŸçš„å—", "éš¾ä»¥ç½®ä¿¡", "å¤ªæ„å¤–äº†"
            ],
            "å®³ç¾": [
                "å®³ç¾", "ä¸å¥½æ„æ€", "è„¸çº¢", "ç¾æ¶©", 
                "ğŸ˜³", "ğŸ˜Š", "shy", "embarrassed",
                "ç¾ç¾", "ä¸å¥½æ„æ€", "éš¾ä¸ºæƒ…"
            ],
            "å®³æ€•": [
                "å®³æ€•", "ææƒ§", "æ€•", "å“äºº", 
                "ğŸ˜¨", "ğŸ˜°", "scared", "afraid",
                "ææ€–", "å¯æ€•", "å“æ­»äº†"
            ]
        }
        
    async def _on_ai_response_start(self, data=None):
        """AIå“åº”å¼€å§‹äº‹ä»¶"""
        self.current_emotion = "neutral"
        self.emotion_intensity = 1.0
        
    async def _on_ai_text_chunk(self, data):
        """AIæ–‡æœ¬å—äº‹ä»¶ - å®æ—¶æƒ…ç»ªåˆ†æ"""
        if not self.enabled:
            return
            
        text = data.get("text", "")
        if text.strip():
            emotion, intensity = self.analyze_emotion(text)
            
            # æ›´æ–°å½“å‰æƒ…ç»ª
            if emotion != "neutral" and emotion != self.current_emotion:
                self.current_emotion = emotion
                self.emotion_intensity = intensity
                
                # å‘å¸ƒæƒ…ç»ªäº‹ä»¶
                await event_bus.publish("live2d_emotion_detected", {
                    "emotion": emotion,
                    "intensity": intensity,
                    "text": text
                })
                
    async def _on_ai_response_end(self, data=None):
        """AIå“åº”ç»“æŸäº‹ä»¶"""
        # é‡ç½®åˆ°ä¸­æ€§æƒ…ç»ª
        await asyncio.sleep(1.0)  # ä¿æŒæƒ…ç»ª1ç§’
        self.current_emotion = "neutral"
        self.emotion_intensity = 1.0
        
    def analyze_emotion(self, text: str) -> Tuple[str, float]:
        """åˆ†ææ–‡æœ¬æƒ…ç»ª"""
        if not text.strip():
            return "neutral", 1.0
            
        text = text.lower()
        emotion_scores = {}
        
        # è®¡ç®—æ¯ç§æƒ…ç»ªçš„å¾—åˆ†
        for emotion, keywords in self.emotion_keywords.items():
            score = 0
            for keyword in keywords:
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œæ¨¡ç³ŠåŒ¹é…
                pattern = re.compile(re.escape(keyword), re.IGNORECASE)
                matches = pattern.findall(text)
                score += len(matches)
            
            if score > 0:
                emotion_scores[emotion] = score
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°æƒ…ç»ªï¼Œè¿”å›ä¸­æ€§
        if not emotion_scores:
            return "neutral", 1.0
            
        # æ‰¾åˆ°å¾—åˆ†æœ€é«˜çš„æƒ…ç»ª
        max_emotion = max(emotion_scores, key=emotion_scores.get)
        max_score = emotion_scores[max_emotion]
        
        # è®¡ç®—å¼ºåº¦ï¼ˆåŸºäºå¾—åˆ†ï¼‰
        intensity = min(max_score / 3.0, 2.0)  # æœ€å¤§å¼ºåº¦ä¸º2.0
        
        return max_emotion, intensity
        
    def get_current_emotion(self) -> Tuple[str, float]:
        """è·å–å½“å‰æƒ…ç»ª"""
        return self.current_emotion, self.emotion_intensity
        
    def set_enabled(self, enabled: bool):
        """å¯ç”¨/ç¦ç”¨æƒ…ç»ªå¤„ç†"""
        self.enabled = enabled
        logger.info(f"æƒ…ç»ªå¤„ç†{'å¯ç”¨' if enabled else 'ç¦ç”¨'}")
```

### æ­¥éª¤3ï¼šAPIæ¥å£é€‚é… - é›†æˆåˆ°NagaAgent

#### 3.1 åˆ›å»ºLive2D APIç«¯ç‚¹

**åœ¨NagaAgentä¸­æ·»åŠ Live2Dä¸“ç”¨çš„APIç«¯ç‚¹**ï¼š
```python
# NagaAgent/apiserver/live2d_api.py
from fastapi import APIRouter, HTTPException, UploadFile, File
from typing import Dict, Any, Optional
import os
import tempfile
import json
import logging
from pydantic import BaseModel

# å¯¼å…¥Live2Dæ¨¡å—
try:
    from live2d_module.live2d_widget import NagaLive2DWidget
    from live2d_module.emotion_handler import Live2DEmotionHandler
    from live2d_module.audio_integration import Live2DAudioAdapter
    LIVE2D_AVAILABLE = True
except ImportError:
    LIVE2D_AVAILABLE = False
    
router = APIRouter()
logger = logging.getLogger("live2d_api")

# è¯·æ±‚æ¨¡å‹
class EmotionRequest(BaseModel):
    emotion: str
    intensity: float = 1.0
    
class TTSRequest(BaseModel):
    text: str
    output_path: Optional[str] = None
    
class Live2DConfigRequest(BaseModel):
    enabled: bool = True
    model_path: Optional[str] = None
    scale: Optional[float] = None
    offset_x: Optional[int] = None
    offset_y: Optional[int] = None
    tts_enabled: Optional[bool] = None
    asr_enabled: Optional[bool] = None
    tts_api_url: Optional[str] = None
    asr_api_url: Optional[str] = None

# å…¨å±€Live2Då®ä¾‹
live2d_widget: Optional[NagaLive2DWidget] = None
emotion_handler: Optional[Live2DEmotionHandler] = None
audio_adapter: Optional[Live2DAudioAdapter] = None

def init_live2d_services(config: Dict[str, Any] = None):
    """åˆå§‹åŒ–Live2DæœåŠ¡"""
    global live2d_widget, emotion_handler, audio_adapter
    
    if not LIVE2D_AVAILABLE:
        logger.warning("Live2Dæ¨¡å—ä¸å¯ç”¨")
        return False
        
    try:
        # åˆå§‹åŒ–æƒ…ç»ªå¤„ç†å™¨
        emotion_handler = Live2DEmotionHandler(config.get("emotion", {}))
        
        # åˆå§‹åŒ–éŸ³é¢‘é€‚é…å™¨
        audio_config = {
            "tts_enabled": config.get("tts_enabled", True),
            "asr_enabled": config.get("asr_enabled", True),
            "tts_api_url": config.get("tts_api_url", "http://127.0.0.1:8000/voice/speak"),
            "asr_api_url": config.get("asr_api_url", "http://127.0.0.1:8000/voice/transcribe")
        }
        audio_adapter = Live2DAudioAdapter(audio_config)
        
        logger.info("Live2DæœåŠ¡åˆå§‹åŒ–å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"Live2DæœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

@router.get("/status")
async def get_live2d_status():
    """è·å–Live2DçŠ¶æ€"""
    return {
        "available": LIVE2D_AVAILABLE,
        "initialized": live2d_widget is not None,
        "emotion_handler_enabled": emotion_handler is not None and emotion_handler.enabled,
        "audio_adapter_enabled": audio_adapter is not None
    }

@router.post("/emotion/trigger")
async def trigger_emotion(request: EmotionRequest):
    """è§¦å‘Live2Dæƒ…ç»ªåŠ¨ä½œ"""
    if not live2d_widget:
        raise HTTPException(status_code=400, detail="Live2Dæ§ä»¶æœªåˆå§‹åŒ–")
        
    try:
        live2d_widget.trigger_emotion(request.emotion, request.intensity)
        return {
            "status": "success", 
            "emotion": request.emotion,
            "intensity": request.intensity
        }
    except Exception as e:
        logger.error(f"è§¦å‘æƒ…ç»ªå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è§¦å‘æƒ…ç»ªå¤±è´¥: {str(e)}")

@router.post("/text-to-speech")
async def text_to_speech(request: TTSRequest):
    """æ–‡æœ¬è½¬è¯­éŸ³"""
    if not audio_adapter:
        raise HTTPException(status_code=400, detail="éŸ³é¢‘é€‚é…å™¨æœªåˆå§‹åŒ–")
        
    try:
        audio_path = await audio_adapter.text_to_speech(request.text, request.output_path)
        if audio_path:
            return {
                "status": "success",
                "audio_path": audio_path,
                "duration": audio_adapter.get_audio_duration(audio_path)
            }
        else:
            raise HTTPException(status_code=500, detail="TTSè½¬æ¢å¤±è´¥")
            
    except Exception as e:
        logger.error(f"TTSè½¬æ¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"TTSè½¬æ¢å¤±è´¥: {str(e)}")

@router.post("/speech-to-text")
async def speech_to_text(audio_file: UploadFile = File(...)):
    """è¯­éŸ³è½¬æ–‡æœ¬"""
    if not audio_adapter:
        raise HTTPException(status_code=400, detail="éŸ³é¢‘é€‚é…å™¨æœªåˆå§‹åŒ–")
        
    try:
        # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
            temp_file.write(await audio_file.read())
            temp_path = temp_file.name
            
        # è¿›è¡Œè¯­éŸ³è¯†åˆ«
        text = await audio_adapter.speech_to_text(temp_path)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.unlink(temp_path)
        
        if text:
            return {
                "status": "success",
                "text": text
            }
        else:
            raise HTTPException(status_code=500, detail="è¯­éŸ³è¯†åˆ«å¤±è´¥")
            
    except Exception as e:
        logger.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")

@router.post("/start-lip-sync")
async def start_lip_sync(audio_file: UploadFile = File(...)):
    """å¼€å§‹å˜´å‹åŒæ­¥"""
    if not live2d_widget:
        raise HTTPException(status_code=400, detail="Live2Dæ§ä»¶æœªåˆå§‹åŒ–")
        
    try:
        # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
            temp_file.write(await audio_file.read())
            temp_path = temp_file.name
            
        # å¼€å§‹å˜´å‹åŒæ­¥
        success = live2d_widget.start_lip_sync(temp_path)
        
        if success:
            return {
                "status": "success",
                "audio_path": temp_path
            }
        else:
            os.unlink(temp_path)
            raise HTTPException(status_code=500, detail="å˜´å‹åŒæ­¥å¯åŠ¨å¤±è´¥")
            
    except Exception as e:
        logger.error(f"å˜´å‹åŒæ­¥å¤±è´¥: {e}")
        if 'temp_path' in locals() and os.path.exists(temp_path):
            os.unlink(temp_path)
        raise HTTPException(status_code=500, detail=f"å˜´å‹åŒæ­¥å¤±è´¥: {str(e)}")

@router.post("/config/update")
async def update_config(request: Live2DConfigRequest):
    """æ›´æ–°Live2Dé…ç½®"""
    try:
        config_updates = request.dict(exclude_unset=True)
        
        # æ›´æ–°Live2Dæ§ä»¶é…ç½®
        if live2d_widget:
            if "scale" in config_updates:
                live2d_widget.scale = config_updates["scale"]
            if "offset_x" in config_updates:
                live2d_widget.model_offset_x = config_updates["offset_x"]
            if "offset_y" in config_updates:
                live2d_widget.model_offset_y = config_updates["offset_y"]
                
        # æ›´æ–°æƒ…ç»ªå¤„ç†å™¨é…ç½®
        if emotion_handler:
            if "enabled" in config_updates:
                emotion_handler.set_enabled(config_updates["enabled"])
                
        # æ›´æ–°éŸ³é¢‘é€‚é…å™¨é…ç½®
        if audio_adapter:
            if "tts_enabled" in config_updates:
                audio_adapter.tts_enabled = config_updates["tts_enabled"]
            if "asr_enabled" in config_updates:
                audio_adapter.asr_enabled = config_updates["asr_enabled"]
            if "tts_api_url" in config_updates:
                audio_adapter.tts_api_url = config_updates["tts_api_url"]
            if "asr_api_url" in config_updates:
                audio_adapter.asr_api_url = config_updates["asr_api_url"]
                
        return {"status": "success", "updated_fields": list(config_updates.keys())}
        
    except Exception as e:
        logger.error(f"æ›´æ–°é…ç½®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ›´æ–°é…ç½®å¤±è´¥: {str(e)}")

@router.get("/config")
async def get_config():
    """è·å–å½“å‰Live2Dé…ç½®"""
    try:
        config = {
            "available": LIVE2D_AVAILABLE,
            "widget_config": {},
            "emotion_config": {},
            "audio_config": {}
        }
        
        if live2d_widget:
            config["widget_config"] = {
                "scale": live2d_widget.scale,
                "offset_x": live2d_widget.model_offset_x,
                "offset_y": live2d_widget.model_offset_y,
                "model_path": live2d_widget.model_path
            }
            
        if emotion_handler:
            config["emotion_config"] = {
                "enabled": emotion_handler.enabled,
                "current_emotion": emotion_handler.current_emotion,
                "emotion_intensity": emotion_handler.emotion_intensity
            }
            
        if audio_adapter:
            config["audio_config"] = {
                "tts_enabled": audio_adapter.tts_enabled,
                "asr_enabled": audio_adapter.asr_enabled,
                "tts_api_url": audio_adapter.tts_api_url,
                "asr_api_url": audio_adapter.asr_api_url
            }
            
        return config
        
    except Exception as e:
        logger.error(f"è·å–é…ç½®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–é…ç½®å¤±è´¥: {str(e)}")
```

#### 3.2 é›†æˆåˆ°NagaAgentä¸»æœåŠ¡å™¨

**ä¿®æ”¹APIæœåŠ¡å™¨**ï¼š
```python
# NagaAgent/apiserver/api_server.py
from fastapi import FastAPI
from .live2d_api import router as live2d_router, init_live2d_services
import logging

logger = logging.getLogger(__name__)

def create_app() -> FastAPI:
    """åˆ›å»ºFastAPIåº”ç”¨"""
    app = FastAPI(title="NagaAgent API Server")
    
    # åŒ…å«ç°æœ‰çš„è·¯ç”±
    # app.include_router(other_router, prefix="/api/v1", tags=["other"])
    
    # åŒ…å«Live2Dè·¯ç”±
    app.include_router(live2d_router, prefix="/api/live2d", tags=["Live2D"])
    
    # æ·»åŠ å¯åŠ¨äº‹ä»¶
    @app.on_event("startup")
    async def startup_event():
        logger.info("å¯åŠ¨NagaAgent APIæœåŠ¡å™¨")
        
        # åˆå§‹åŒ–Live2DæœåŠ¡
        live2d_config = {
            "emotion": {"enabled": True},
            "tts_enabled": True,
            "asr_enabled": True,
            "tts_api_url": "http://127.0.0.1:8000/voice/speak",
            "asr_api_url": "http://127.0.0.1:8000/voice/transcribe"
        }
        
        init_live2d_services(live2d_config)
        
    return app
```

#### 3.2 å¯¹è¯ç³»ç»Ÿé›†æˆ

**ä¿®æ”¹å¯¹è¯æ ¸å¿ƒä»¥æ”¯æŒLive2Dæƒ…ç»ªåˆ†æ**ï¼š
```python
# NagaAgent/conversation_core.py
class NagaConversation:
    def __init__(self):
        self.live2d_enabled = True  # æ˜¯å¦å¯ç”¨Live2D
        
    async def generate_response(self, message: str, session_id: str = None):
        """ç”Ÿæˆå“åº”å¹¶å¤„ç†Live2Dæƒ…ç»ª"""
        # åŸæœ‰çš„å¯¹è¯é€»è¾‘
        response = await self.llm_generate(message, session_id)
        
        # å¦‚æœå¯ç”¨äº†Live2Dï¼Œåˆ†ææƒ…ç»ªå¹¶è§¦å‘åŠ¨ä½œ
        if self.live2d_enabled:
            await self.analyze_and_trigger_emotion(response)
            
        return response
        
    async def analyze_and_trigger_emotion(self, text: str):
        """åˆ†ææ–‡æœ¬æƒ…ç»ªå¹¶è§¦å‘Live2DåŠ¨ä½œ"""
        # ç®€å•çš„æƒ…ç»ªåˆ†æï¼ˆå¯ä»¥æ›¿æ¢ä¸ºæ›´å¤æ‚çš„NLPåˆ†æï¼‰
        emotion_keywords = {
            "å¼€å¿ƒ": ["å¼€å¿ƒ", "é«˜å…´", "å¿«ä¹", "å“ˆå“ˆ", "ğŸ˜Š", "ğŸ™‚"],
            "ç”Ÿæ°”": ["ç”Ÿæ°”", "æ„¤æ€’", "è®¨åŒ", "ğŸ˜ ", "ğŸ˜¡"],
            "ä¼¤å¿ƒ": ["ä¼¤å¿ƒ", "éš¾è¿‡", "æ‚²ä¼¤", "ğŸ˜¢", "ğŸ˜­"],
            "æƒŠè®¶": ["æƒŠè®¶", "éœ‡æƒŠ", "å“‡", "å¤©å•Š", "ğŸ˜®", "ğŸ˜²"],
            "å®³ç¾": ["å®³ç¾", "ä¸å¥½æ„æ€", "è„¸çº¢", "ğŸ˜³"]
        }
        
        detected_emotion = "neutral"
        max_score = 0
        
        for emotion, keywords in emotion_keywords.items():
            score = sum(1 for keyword in keywords if keyword in text)
            if score > max_score:
                max_score = score
                detected_emotion = emotion
                
        # è§¦å‘Live2Dæƒ…ç»ª
        await self.trigger_live2d_emotion(detected_emotion)
        
    async def trigger_live2d_emotion(self, emotion: str, intensity: float = 1.0):
        """è§¦å‘Live2Dæƒ…ç»ªåŠ¨ä½œ"""
        try:
            # é€šè¿‡HTTP APIè§¦å‘æƒ…ç»ª
            import aiohttp
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "http://127.0.0.1:8000/live2d/emotion/trigger",
                    json={"emotion": emotion, "intensity": intensity}
                ) as response:
                    if response.status == 200:
                        print(f"Live2Dæƒ…ç»ªè§¦å‘æˆåŠŸ: {emotion}")
        except Exception as e:
            print(f"Live2Dæƒ…ç»ªè§¦å‘å¤±è´¥: {e}")
```

### æ­¥éª¤4ï¼šUIé›†æˆ

#### 4.1 æ–¹æ¡ˆä¸€ï¼šç‹¬ç«‹Electronåº”ç”¨

**åˆ›å»ºå¯åŠ¨è„šæœ¬**ï¼š
```python
# NagaAgent/live2d_frontend/js_version/start_live2d.py
import subprocess
import os
import sys
from pathlib import Path

def start_live2d_frontend():
    """å¯åŠ¨Live2Då‰ç«¯åº”ç”¨"""
    live2d_dir = Path(__file__).parent / "js_version"
    
    # æ£€æŸ¥Node.jsç¯å¢ƒ
    try:
        subprocess.run(["node", "--version"], check=True, capture_output=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("è¯·å…ˆå®‰è£…Node.js")
        return
        
    # å®‰è£…ä¾èµ–
    os.chdir(live2d_dir)
    if not (live2d_dir / "node_modules").exists():
        print("å®‰è£…Live2Då‰ç«¯ä¾èµ–...")
        subprocess.run(["npm", "install"], check=True)
        
    # å¯åŠ¨åº”ç”¨
    print("å¯åŠ¨Live2Då‰ç«¯...")
    subprocess.run(["npm", "start"])

if __name__ == "__main__":
    start_live2d_frontend()
```

**é›†æˆåˆ°NagaAgentä¸»ç¨‹åº**ï¼š
```python
# NagaAgent/main.py
import threading
import time
from live2d_frontend.js_version.start_live2d import start_live2d_frontend

class NagaAgent:
    def __init__(self):
        self.live2d_process = None
        
    def start_live2d_frontend(self):
        """å¯åŠ¨Live2Då‰ç«¯"""
        def run_live2d():
            start_live2d_frontend()
            
        self.live2d_thread = threading.Thread(target=run_live2d, daemon=True)
        self.live2d_thread.start()
        
    def start(self):
        """å¯åŠ¨NagaAgent"""
        # å¯åŠ¨Live2Då‰ç«¯
        if config.live2d.enabled:
            self.start_live2d_frontend()
            time.sleep(2)  # ç­‰å¾…Live2Då‰ç«¯å¯åŠ¨
            
        # å¯åŠ¨å…¶ä»–æœåŠ¡...
```

#### 4.2 æ–¹æ¡ˆäºŒï¼šé›†æˆåˆ°PyQtç•Œé¢

**ä¿®æ”¹ä¸»èŠå¤©çª—å£**ï¼š
```python
# NagaAgent/ui/pyqt_chat_window.py
from ..live2d_frontend.py_version.live2d_widget import Live2DWidget

class ChatWindow(QWidget):
    def __init__(self):
        super().__init__()
        
        # åˆ›å»ºä¸»å¸ƒå±€
        self.main_layout = QHBoxLayout()
        
        # åˆ›å»ºLive2Dæ§ä»¶
        self.live2d_widget = Live2DWidget()
        self.live2d_widget.setFixedSize(400, 600)
        
        # åˆ›å»ºèŠå¤©åŒºåŸŸ
        self.chat_area = QWidget()
        
        # æ·»åŠ åˆ°å¸ƒå±€
        self.main_layout.addWidget(self.live2d_widget, 1)  # 30%å®½åº¦
        self.main_layout.addWidget(self.chat_area, 2)       # 70%å®½åº¦
        
        self.setLayout(self.main_layout)
        
    def on_message_received(self, message):
        """æ”¶åˆ°æ¶ˆæ¯æ—¶çš„å¤„ç†"""
        # æ˜¾ç¤ºæ¶ˆæ¯
        self.display_message(message)
        
        # è§¦å‘Live2Dæƒ…ç»ª
        emotion = self.analyze_emotion(message)
        self.live2d_widget.trigger_emotion(emotion)
```

### æ­¥éª¤5ï¼šé…ç½®ç³»ç»Ÿé›†æˆ

#### 5.1 æ‰©å±•é…ç½®æ–‡ä»¶

**åœ¨NagaAgenté…ç½®ä¸­æ·»åŠ Live2Dç›¸å…³é…ç½®**ï¼š
```python
# NagaAgent/config.py
class Live2DConfig(BaseModel):
    """Live2Dé…ç½®"""
    enabled: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨Live2D")
    frontend_type: str = Field(default="electron", description="å‰ç«¯ç±»å‹: electron/pyqt")
    model_path: str = Field(default="live2d_frontend/shared/models/hiyori_pro_mic.model3.json", description="Live2Dæ¨¡å‹è·¯å¾„")
    auto_start: bool = Field(default=True, description="æ˜¯å¦è‡ªåŠ¨å¯åŠ¨")
    emotion_analysis: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨æƒ…ç»ªåˆ†æ")
    lip_sync: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨å˜´å‹åŒæ­¥")
    scale: float = Field(default=0.25, description="æ¨¡å‹ç¼©æ”¾æ¯”ä¾‹")
    position: Dict[str, float] = Field(default={"x": 0.5, "y": 0.5}, description="æ¨¡å‹ä½ç½®")

class UIConfig(BaseModel):
    """UIé…ç½®"""
    bg_alpha: float = Field(default=0.3, description="èƒŒæ™¯é€æ˜åº¦")
    window_bg_alpha: float = Field(default=0.95, description="çª—å£èƒŒæ™¯é€æ˜åº¦")
    user_name: str = Field(default="ç”¨æˆ·", description="ç”¨æˆ·å")
    live2d: Live2DConfig = Field(default_factory=Live2DConfig, description="Live2Dé…ç½®")
```

#### 5.2 åˆ›å»ºé…ç½®ç®¡ç†å·¥å…·

**Live2Dé…ç½®ç®¡ç†ç•Œé¢**ï¼š
```python
# NagaAgent/ui/live2d_settings.py
from PyQt5.QtWidgets import (QWidget, QVBoxLayout, QHBoxLayout, QLabel, 
                            QComboBox, QCheckBox, QSlider, QPushButton)
from config import config

class Live2DSettingsWidget(QWidget):
    """Live2Dè®¾ç½®æ§ä»¶"""
    
    def __init__(self):
        super().__init__()
        self.setup_ui()
        
    def setup_ui(self):
        layout = QVBoxLayout()
        
        # å‰ç«¯ç±»å‹é€‰æ‹©
        frontend_layout = QHBoxLayout()
        frontend_layout.addWidget(QLabel("å‰ç«¯ç±»å‹:"))
        self.frontend_combo = QComboBox()
        self.frontend_combo.addItems(["electron", "pyqt"])
        self.frontend_combo.setCurrentText(config.ui.live2d.frontend_type)
        frontend_layout.addWidget(self.frontend_combo)
        layout.addLayout(frontend_layout)
        
        # å¯ç”¨å¼€å…³
        self.enabled_checkbox = QCheckBox("å¯ç”¨Live2D")
        self.enabled_checkbox.setChecked(config.ui.live2d.enabled)
        layout.addWidget(self.enabled_checkbox)
        
        # æƒ…ç»ªåˆ†æå¼€å…³
        self.emotion_checkbox = QCheckBox("æƒ…ç»ªåˆ†æ")
        self.emotion_checkbox.setChecked(config.ui.live2d.emotion_analysis)
        layout.addWidget(self.emotion_checkbox)
        
        # å˜´å‹åŒæ­¥å¼€å…³
        self.lip_sync_checkbox = QCheckBox("å˜´å‹åŒæ­¥")
        self.lip_sync_checkbox.setChecked(config.ui.live2d.lip_sync)
        layout.addWidget(self.lip_sync_checkbox)
        
        # ç¼©æ”¾æ»‘å—
        scale_layout = QHBoxLayout()
        scale_layout.addWidget(QLabel("ç¼©æ”¾æ¯”ä¾‹:"))
        self.scale_slider = QSlider(Qt.Horizontal)
        self.scale_slider.setRange(10, 100)
        self.scale_slider.setValue(int(config.ui.live2d.scale * 100))
        scale_layout.addWidget(self.scale_slider)
        layout.addLayout(scale_layout)
        
        # ä¿å­˜æŒ‰é’®
        self.save_button = QPushButton("ä¿å­˜è®¾ç½®")
        self.save_button.clicked.connect(self.save_settings)
        layout.addWidget(self.save_button)
        
        layout.addStretch()
        self.setLayout(layout)
        
    def save_settings(self):
        """ä¿å­˜è®¾ç½®"""
        config.ui.live2d.frontend_type = self.frontend_combo.currentText()
        config.ui.live2d.enabled = self.enabled_checkbox.isChecked()
        config.ui.live2d.emotion_analysis = self.emotion_checkbox.isChecked()
        config.ui.live2d.lip_sync = self.lip_sync_checkbox.isChecked()
        config.ui.live2d.scale = self.scale_slider.value() / 100
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        config.save_config()
```

### æ­¥éª¤6ï¼šä¾èµ–ç®¡ç†

#### 6.1 æ›´æ–°ä¾èµ–æ–‡ä»¶

**åœ¨requirements.txtä¸­æ·»åŠ Live2Dç›¸å…³ä¾èµ–**ï¼š
```
# Live2Dç›¸å…³ä¾èµ–
# å¦‚æœä½¿ç”¨Pythonç‰ˆæœ¬çš„Live2D
live2d-v3>=0.1.0
pyopengl>=3.1.0
pyopengl-accelerate>=3.1.0

# å¦‚æœä½¿ç”¨JavaScriptç‰ˆæœ¬ï¼Œéœ€è¦Node.jsç¯å¢ƒ
# npmä¾èµ–åœ¨live2d_frontend/js_version/package.jsonä¸­ç®¡ç†

# éŸ³é¢‘å¤„ç†ä¾èµ–
pyaudio>=0.2.11
numpy>=1.21.0

# WebSocketæ”¯æŒ
websockets>=10.0
aiohttp>=3.8.0
```

**åˆ›å»ºJavaScriptç‰ˆæœ¬çš„package.json**ï¼š
```json
{
  "name": "nagaagent-live2d",
  "version": "1.0.0",
  "description": "NagaAgent Live2D Frontend",
  "main": "main.js",
  "scripts": {
    "start": "electron .",
    "build": "electron-builder",
    "dev": "electron . --dev"
  },
  "dependencies": {
    "electron": "^25.0.0",
    "pixi.js": "^7.3.0",
    "pixi-live2d-display": "^0.4.0",
    "live2d-widget": "^3.2.0"
  },
  "devDependencies": {
    "electron-builder": "^24.0.0"
  }
}
```

### æ­¥éª¤7ï¼šæµ‹è¯•å’Œè°ƒè¯•

#### 7.1 å•å…ƒæµ‹è¯•

**åˆ›å»ºæµ‹è¯•è„šæœ¬**ï¼š
```python
# NagaAgent/tests/test_live2d.py
import unittest
import asyncio
from unittest.mock import Mock, patch

class TestLive2DIntegration(unittest.TestCase):
    """Live2Dé›†æˆæµ‹è¯•"""
    
    def setUp(self):
        self.conversation = NagaConversation()
        
    def test_emotion_analysis(self):
        """æµ‹è¯•æƒ…ç»ªåˆ†æ"""
        test_cases = [
            ("ä»Šå¤©çœŸå¼€å¿ƒï¼", "å¼€å¿ƒ"),
            ("æˆ‘ç”Ÿæ°”äº†", "ç”Ÿæ°”"),
            ("å¤ªéœ‡æƒŠäº†", "æƒŠè®¶")
        ]
        
        for text, expected_emotion in test_cases:
            with patch.object(self.conversation, 'trigger_live2d_emotion') as mock_trigger:
                asyncio.run(self.conversation.analyze_and_trigger_emotion(text))
                mock_trigger.assert_called_once()
                
    def test_live2d_api_integration(self):
        """æµ‹è¯•Live2D APIé›†æˆ"""
        with patch('aiohttp.ClientSession.post') as mock_post:
            mock_post.return_value.__aenter__.return_value.status = 200
            
            asyncio.run(self.conversation.trigger_live2d_emotion("å¼€å¿ƒ"))
            
            mock_post.assert_called_once()
            call_args = mock_post.call_args
            self.assertIn("emotion", call_args[1]['json'])

if __name__ == "__main__":
    unittest.main()
```

#### 7.2 é›†æˆæµ‹è¯•

**åˆ›å»ºå®Œæ•´çš„æµ‹è¯•æµç¨‹**ï¼š
```python
# NagaAgent/tests/test_integration.py
import pytest
import subprocess
import time
import requests

class TestLive2DFullIntegration:
    """Live2Då®Œæ•´é›†æˆæµ‹è¯•"""
    
    @pytest.fixture(scope="class")
    def nagaagent_server(self):
        """å¯åŠ¨NagaAgentæœåŠ¡å™¨"""
        server_process = subprocess.Popen(["python", "main.py"])
        time.sleep(5)  # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
        yield server_process
        server_process.terminate()
        
    @pytest.fixture(scope="class")
    def live2d_frontend(self):
        """å¯åŠ¨Live2Då‰ç«¯"""
        frontend_process = subprocess.Popen([
            "python", 
            "live2d_frontend/js_version/start_live2d.py"
        ])
        time.sleep(3)  # ç­‰å¾…å‰ç«¯å¯åŠ¨
        yield frontend_process
        frontend_process.terminate()
        
    def test_end_to_end_integration(self, nagaagent_server, live2d_frontend):
        """ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•"""
        # æµ‹è¯•APIå¥åº·æ£€æŸ¥
        response = requests.get("http://127.0.0.1:8000/health")
        assert response.status_code == 200
        
        # æµ‹è¯•å¯¹è¯åŠŸèƒ½
        chat_response = requests.post(
            "http://127.0.0.1:8000/chat",
            json={"message": "ä½ å¥½ï¼Œæµ‹è¯•ä¸€ä¸‹"}
        )
        assert chat_response.status_code == 200
        
        # æµ‹è¯•Live2Dæƒ…ç»ªè§¦å‘
        emotion_response = requests.post(
            "http://127.0.0.1:8000/live2d/emotion/trigger",
            json={"emotion": "happy", "intensity": 1.0}
        )
        assert emotion_response.status_code == 200
```

### æ­¥éª¤8ï¼šéƒ¨ç½²å’Œæ‰“åŒ…

#### 8.1 åˆ›å»ºå®‰è£…è„šæœ¬

**Windowså®‰è£…è„šæœ¬**ï¼š
```batch
@echo off
echo æ­£åœ¨å®‰è£…Live2Då‰ç«¯ä¾èµ–...

cd /d NagaAgent\live2d_frontend\js_version

echo æ£€æŸ¥Node.jsç¯å¢ƒ...
node --version
if errorlevel 1 (
    echo è¯·å…ˆå®‰è£…Node.js
    pause
    exit /b 1
)

echo å®‰è£…npmä¾èµ–...
call npm install

echo å®‰è£…å®Œæˆ!
pause
```

**åˆ›å»ºå¯åŠ¨è„šæœ¬**ï¼š
```batch
@echo off
echo å¯åŠ¨NagaAgent with Live2D...

cd /d NagaAgent

:: å¯åŠ¨Live2Då‰ç«¯
start "Live2D Frontend" cmd /k "python live2d_frontend/js_version/start_live2d.py"

:: ç­‰å¾…å‰ç«¯å¯åŠ¨
timeout /t 3

:: å¯åŠ¨NagaAgentä¸»ç¨‹åº
start "NagaAgent" cmd /k "python main.py"

echo æ‰€æœ‰æœåŠ¡å·²å¯åŠ¨!
pause
```

#### 8.2 æ‰“åŒ…é…ç½®

**ä¿®æ”¹Electronæ‰“åŒ…é…ç½®**ï¼š
```json
{
  "build": {
    "appId": "com.nagaagent.live2d",
    "productName": "NagaAgent Live2D",
    "directories": {
      "output": "dist"
    },
    "files": [
      "**/*",
      "!**/node_modules/*/{CHANGELOG.md,README.md,README,readme.md,readme}",
      "!**/node_modules/*/{test,__tests__,tests,powered-test,example,examples}",
      "!**/node_modules/*.d.ts",
      "!**/node_modules/.bin",
      "!**/*.{iml,o,hprof,orig,pyc,pyo,rbc,swp,csproj,sln,xproj}",
      "!.editorconfig",
      "!**/._*",
      "!**/{.DS_Store,.git,.hg,.svn,CVS,RCS,SCCS,.gitignore,.gitattributes}",
      "!**/{__pycache__,thumbs.db,.flowconfig,.idea,.vs,.nyc_output}",
      "!**/{appveyor.yml,.travis.yml,circle.yml}",
      "!**/{npm-debug.log,yarn.lock,.yarn-integrity,.yarn-metadata.json}"
    ],
    "extraResources": [
      {
        "from": "../shared/models",
        "to": "models",
        "filter": ["**/*"]
      }
    ]
  }
}
```

## æ¨èå®æ–½æ–¹æ¡ˆ

åŸºäºé¡¹ç›®å¤æ‚åº¦å’Œç»´æŠ¤æ€§è€ƒè™‘ï¼Œ**æ¨èä½¿ç”¨æ–¹æ¡ˆä¸€ï¼ˆJavaScriptç‰ˆæœ¬ï¼‰**ï¼Œç†ç”±å¦‚ä¸‹ï¼š

### ä¼˜åŠ¿ï¼š
1. **ä¿æŒåŸæœ‰åŠŸèƒ½**ï¼šMy-Neuroçš„Live2Då®ç°å·²ç»å¾ˆæˆç†Ÿï¼Œç›´æ¥ç§»æ¤å‡å°‘å¼€å‘é£é™©
2. **ç‹¬ç«‹ç»´æŠ¤**ï¼šLive2Då‰ç«¯ä½œä¸ºç‹¬ç«‹æ¨¡å—ï¼Œä¸å½±å“NagaAgentæ ¸å¿ƒåŠŸèƒ½
3. **æŠ€æœ¯æˆç†Ÿ**ï¼šElectron + PIXI.jsçš„Live2Då®ç°æ¯”Pythonç‰ˆæœ¬æ›´ç¨³å®š
4. **æ‰©å±•æ€§å¥½**ï¼šæœªæ¥å¯ä»¥ç‹¬ç«‹å‡çº§Live2Då‰ç«¯è€Œä¸å½±å“åç«¯

### å®æ–½ä¼˜å…ˆçº§ï¼š
1. **ç¬¬ä¸€é˜¶æ®µ**ï¼šç§»æ¤JavaScriptç‰ˆæœ¬ï¼Œå®ç°åŸºæœ¬Live2Dæ˜¾ç¤º
2. **ç¬¬äºŒé˜¶æ®µ**ï¼šé›†æˆæƒ…ç»ªåˆ†æå’ŒåŠ¨ä½œè§¦å‘
3. **ç¬¬ä¸‰é˜¶æ®µ**ï¼šå®ç°å˜´å‹åŒæ­¥å’ŒéŸ³é¢‘é›†æˆ
4. **ç¬¬å››é˜¶æ®µ**ï¼šä¼˜åŒ–æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒ

## æ³¨æ„äº‹é¡¹

1. **Live2D SDKè®¸å¯**ï¼šç¡®ä¿Live2D SDKçš„ä½¿ç”¨ç¬¦åˆè®¸å¯åè®®
2. **æ¨¡å‹æ–‡ä»¶ç‰ˆæƒ**ï¼šLive2Dæ¨¡å‹æ–‡ä»¶å¯èƒ½æœ‰ç‰ˆæƒé™åˆ¶ï¼Œéœ€è¦ç¡®è®¤ä½¿ç”¨æƒé™
3. **æ€§èƒ½ä¼˜åŒ–**ï¼šLive2Dæ¸²æŸ“å¯èƒ½å ç”¨è¾ƒå¤šç³»ç»Ÿèµ„æºï¼Œéœ€è¦åšå¥½æ€§èƒ½ä¼˜åŒ–
4. **é”™è¯¯å¤„ç†**ï¼šåšå¥½Live2Då‰ç«¯ä¸åç«¯é€šä¿¡çš„é”™è¯¯å¤„ç†å’Œé™çº§æ–¹æ¡ˆ
5. **ç”¨æˆ·ä½“éªŒ**ï¼šæä¾›å¼€å…³é€‰é¡¹ï¼Œè®©ç”¨æˆ·å¯ä»¥é€‰æ‹©æ˜¯å¦å¯ç”¨Live2DåŠŸèƒ½

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜ï¼š
1. **Node.jsç‰ˆæœ¬ä¸å…¼å®¹**ï¼šç¡®ä¿ä½¿ç”¨Node.js 16+
2. **Live2Dæ¨¡å‹åŠ è½½å¤±è´¥**ï¼šæ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„å’Œæ ¼å¼
3. **WebSocketè¿æ¥å¤±è´¥**ï¼šæ£€æŸ¥é˜²ç«å¢™å’Œç«¯å£è®¾ç½®
4. **éŸ³é¢‘åŒæ­¥é—®é¢˜**ï¼šæ£€æŸ¥éŸ³é¢‘æ ¼å¼å’Œæ’­æ”¾å™¨å…¼å®¹æ€§

### è°ƒè¯•å·¥å…·ï¼š
1. **å¼€å‘è€…å·¥å…·**ï¼šElectronåº”ç”¨å¯ä»¥ä½¿ç”¨Chromeå¼€å‘è€…å·¥å…·
2. **æ—¥å¿—ç³»ç»Ÿ**ï¼šå¯ç”¨è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—
3. **æ€§èƒ½ç›‘æ§**ï¼šä½¿ç”¨Chrome Performanceé¢æ¿ç›‘æ§æ¸²æŸ“æ€§èƒ½

é€šè¿‡ä»¥ä¸Šæ­¥éª¤ï¼Œä½ å¯ä»¥æˆåŠŸå°†My-Neuroçš„å‰ç«¯æ•°å­—äººåŠŸèƒ½ç§»æ¤åˆ°NagaAgenté¡¹ç›®ä¸­ï¼Œä¸ºç”¨æˆ·æä¾›æ›´åŠ ä¸°å¯Œçš„äº¤äº’ä½“éªŒã€‚